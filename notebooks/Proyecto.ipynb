import pandas as pd
import numpy as np
import requests
import os
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import joblib  # Para guardar el modelo (Objetivo 5)

# Configuración
plt.style.use('ggplot')
pd.options.display.float_format = '{:,.0f}'.format

print(" INICIANDO EJECUCIÓN ALINEADA A OBJETIVOS...")

# --- 1. OBJETIVO: ETL AUTOMATIZADO ---
archivo = "secop_2024_final.csv"
# Descargamos una muestra robusta para filtrar localmente
url = "https://www.datos.gov.co/resource/p6dx-8zbt.csv?$limit=100000"

if not os.path.exists(archivo):
    print("⬇  Ejecutando ETL: Extracción desde API...")
    try:
        r = requests.get(url)
        with open(archivo, 'wb') as f: f.write(r.content)
        print(" Datos extraídos y cargados localmente.")
    except: print(" Error de conexión.")
else:
    print("ℹ  Usando caché local.")

print(" Ejecutando ETL: Transformación y Limpieza...")
df = pd.read_csv(archivo, low_memory=False)

# Detección de columnas y Limpieza
cols = [c.lower() for c in df.columns]
df.columns = cols
col_val = next((c for c in cols if 'valor' in c or 'cuantia' in c), 'valor_total_adjudicacion')
col_fecha = next((c for c in cols if 'fecha' in c and ('firma' in c or 'adjudicacion' in c)), 'fecha_adjudicacion')
col_dep = next((c for c in cols if 'departamento' in c), 'departamento_entidad')
col_nit = next((c for c in cols if 'nit' in c), 'nit_entidad')
col_ent = next((c for c in cols if 'entidad' in c and 'nit' not in c), 'entidad')
col_mod = next((c for c in cols if 'modalidad' in c), 'modalidad_de_contratacion')

# Filtro Año 2024
df[col_fecha] = pd.to_datetime(df[col_fecha], errors='coerce')
df = df[df[col_fecha].dt.year == 2024]

# Limpieza Valores
if df[col_val].dtype == 'O':
    df[col_val] = df[col_val].astype(str).str.replace(r'[$,]', '', regex=True)
df[col_val] = pd.to_numeric(df[col_val], errors='coerce')
df = df[df[col_val] > 0]

# --- 2. OBJETIVO: ANÁLISIS EXPLORATORIO (EDA) ---
print(" Generando Gráficos EDA (Para el documento)...")

fig, axs = plt.subplots(1, 3, figsize=(18, 5))

# Gráfico 1: Modalidades
df[col_mod].value_counts().head(5).plot(kind='bar', ax=axs[0], color='teal')
axs[0].set_title('A. Top 5 Modalidades (2024)')
axs[0].set_ylabel('Cantidad de Contratos')

# Gráfico 2: Ubicación Geográfica
df[col_dep].value_counts().head(5).plot(kind='barh', ax=axs[1], color='orange')
axs[1].set_title('B. Top 5 Departamentos')

# Gráfico 3: Distribución de Montos (Histograma Log)
sns.histplot(df[col_val], bins=30, log_scale=True, ax=axs[2], color='purple')
axs[2].set_title('C. Distribución de Valores (Escala Log)')

plt.tight_layout()
plt.show()

# --- 3. OBJETIVO: INGENIERÍA DE CARACTERÍSTICAS (POR ENTIDAD) ---
print("  Calculando Features por Entidad...")

# Variable Dummy para Modalidad Directa
df['es_directa'] = df[col_mod].astype(str).apply(lambda x: 1 if 'Directa' in x or 'directa' in x else 0)

# Agrupación (La transformación clave)
df_ent = df.groupby(col_nit).agg({
    col_ent: 'first',
    col_val: ['sum', 'mean'],     # Feature 1 y 2: Monto Total y Promedio
    col_nit: 'count',             # Feature 3: Frecuencia
    'es_directa': 'mean'          # Feature 4: % Contratación Directa
}).reset_index()

df_ent.columns = ['nit', 'nombre', 'monto_total', 'monto_promedio', 'num_contratos', 'pct_directa']
df_ent = df_ent[df_ent['monto_total'] > 0]

# --- 4. OBJETIVO: SEGMENTACIÓN K-MEANS ---
print(" Entrenando Modelo K-Means...")

# Selección de variables para el modelo
features = ['monto_total', 'num_contratos', 'pct_directa']
X = df_ent[features]

# Estandarización (Obligatorio)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Método del Codo (Para justificar K en la tesis)
wcss = []
for i in range(1, 11):
    kmeans = KMeans(n_clusters=i, random_state=42, n_init=10)
    kmeans.fit(X_scaled)
    wcss.append(kmeans.inertia_)

# Entrenar Modelo Final (K=4)
kmeans_final = KMeans(n_clusters=4, random_state=42, n_init=10)
df_ent['cluster'] = kmeans_final.fit_predict(X_scaled)

# --- GUARDAR MODELO PARA EL PROTOTIPO ---
print(" Guardando archivos para el Prototipo...")
joblib.dump(kmeans_final, 'modelo_kmeans.pkl')
joblib.dump(scaler, 'escalador.pkl')
print("Archivos 'modelo_kmeans.pkl' y 'escalador.pkl' guardados.")

# --- RESULTADOS ---
print("\n" + "="*60)
print("RESULTADOS FINALES (CENTROIDES)")
print("="*60)
print(df_ent.groupby('cluster')[features].mean())
print("\nEJEMPLOS:")
for i in range(4):
    print(f"Cluster {i}: {df_ent[df_ent['cluster']==i]['nombre'].head(2).tolist()}")

# Gráfico del Codo (Para mostrar que se analizó el K óptimo)
plt.figure(figsize=(6, 4))
plt.plot(range(1, 11), wcss, marker='o')
plt.title('Método del Codo (Justificación de K)')
plt.xlabel('Número de Clusters')
plt.ylabel('Inercia')
plt.show()

from sklearn.metrics import silhouette_score

# Asegúrate de tener X_scaled y df_ent['cluster'] listos (del script anterior)
print(" Calculando Coeficiente de Silueta...")
score = silhouette_score(X_scaled, df_ent['cluster'])
print(f" Coeficiente de Silueta del modelo: {score:.3f}")

if score > 0.5:
    print("INTERPRETACIÓN: Los clusters están bien definidos y separados.")
elif score > 0.25:
    print("INTERPRETACIÓN: La estructura es razonable, aunque hay solapamiento.")
else:
    print("INTERPRETACIÓN: Los clusters son débiles o los datos están muy dispersos.")
